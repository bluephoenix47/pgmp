Review A asks about the performance of optimized programs.  We
considered at length how to address this issue while preparing the
paper and concluded there was not much useful we could say.  The
optimizations used in our case studies have been found to be effective
in the literature, and a performance evaluation in our system would
measure the specifics of our Racket and Chez Scheme implementations
more than the benefits of our technique.  Furthermore, since some
of the more interesting optimizations performed at the level of
meta programs can change asymptotic behavior (for example, optimizations
that select algorithms or data representations based on frequency
of operations) it would be easy to create examples with arbitrary
performance improvements, which would uninformative at best.

Profiling overhead is specific to the profiler used by the
implementation of our technique.  Previous work measured about 9%
overhead of profiler we use in our Chez Scheme implementation [2].
The profiling library used in our Racket implementation has overhead
ranging from 3% to 33% [1].  In the typical workflow, profiling is
disabled for production runs of a program, so this overhead affects
only profiled runs during development.

Review A also asks about compile-time overhead.  The overhead for
loading profile information is linear in the number of source points,
and the overhead for determining the weight of a particular source
point is constant-time.  In both cases, the cost per source point
is small---a hash-table write or read.  The overhead for performing
an optimization based on profile information will be specific to
the optimization. For instance, conditional branch reordering is a
simple local change and will likely not have much overhead.  Performing
function inlining as a profile-guided meta-program might be more
costly; the meta-program must account for global changes to code
size, may be run many times depending on the number of function
calls, and may slow down (or speed up) later stages of compilation.

We will add a discussion of these issues to the final paper.

Review A asks if the meta-programming approach is general enough to
permit path and locality profiling. As long as costs measured by the
profiler can be mapped to source program points, our techniques should
apply. Path profiling can inform optimizations such as inlining,
which can be expressed using our technique.  We conjecture locality
information is better used by low level optimizations.  However, it is
possible that some clever meta-programs could take advantage of locality
profiling in our system.

Review A notes that we do not discuss how profiling or meta-programming
work in other meta-programming systems, such as Template Haskell or
MetaML. We will add a discussion of other meta-programming systems and
how our technique might apply to them.

Review A mentions aspect-oriented programming, which can be used to
insert profiling code. Aspect-oriented programming (AOP) is orthogonal
to meta-programming. Our technique should work with an AOP based
profiler, so long as profile points can be mapped to program points.

Review B states that the design and development of the idea is too
narrow for a conference such as PLDI.  We respectfully disagree.
This work combines two techniques, profile guided optimization and
meta-programming, which frequently appear at PLDI, into a single
general-purpose approach: Pettis and Hansen (PLDI 1990 most influential
paper award); Frigo (PLDI 1999 most influential paper award); Chen
et al. (PLDI 2006), Hawkins et al. (PLDI 2011, PLDI 2012).  If the
mechanism seems straightforward to use or even to implement, that
should be viewed as a positive, both in regard to the mechanism and
in regard to our description of it.

Review C asks we ensure that profile points are not mixed up,
for instance, when reordering conditional branches. In our
implementations, profile points are introduced in two ways:

1) The language parser attaches source location information (filename, line
number, character position) to each source expression. We use this
source location to uniquely identify profile points. These profile
points are always generated deterministically. As they are attached
directed to the source expressions we transform, they are implicitly
preserved during meta-programming code transformations.

2) The meta-program explicitly introduces a new profile point with
make-profile-point. In this case, make-profile-point must generate the
profile point deterministically. Otherwise, when later runs lookup
profile information for a generated profile point, the results may be
arbitrary. In our implementations, we solve this by providing
make-profile-point a source expression as input, and use the source
location information as a starting point to deterministically generate
new profile points.

In both cases, source information is attached directly to
intermediate-langauge forms in all the downstream passes leading
to the insertion of profile counters, which are themselves connected
to the source information in the generated code.  The intermediate-language
forms can thus be reordered or replicated by downstream passes
without any concern about the compiler losing track of the source
correlation.  The final paper will elaborate on this.


[1] http://www.ccs.neu.edu/racket/pubs/NU-CCIS-14-01.pdf

[2] Robert G Burger and R Kent Dybvig. An infrastructure for profile-
driven dynamic recompilation. In Proc. Computer Languages, 1998.
Proceedings. 1998 International Conference on, 1998.
http://www.cs.indiana.edu/~dyb/pubs/pdrtc.pdf

[3] http://www.sigplan.org/Awards/PLDI/

[4] Wen-ke Chen, Sanjay Bhansali, Trishul Chilimbi, Xiaofeng Gao, and Weihaw
Chuang. Profile-guided Proactive Garbage Collec- tion for Locality
Optimization. In Proc. The 2006 ACM SIG- PLAN Conference on Programming
Language Design and Im- plementation, 2006b. http://doi.acm.org/10.1145/
1133981.1134021

[5] Peter Hawkins, Alex Aiken, Kathleen Fisher, Martin Rinard, and Mooly
Sagiv. Data Representation Synthesis. In Proc. Proceed- ings of the 32Nd
ACM SIGPLAN Conference on Programming Language Design and
Implementation, 2011. http://doi. acm.org/10.1145/1993498.1993504

[6] Peter Hawkins, Alex Aiken, Kathleen Fisher, Martin Rinard, and Mooly
Sagiv. Concurrent Data Representation Synthesis. In Proc. Proceedings of
the 33rd ACM SIGPLAN Conference on Programming Language Design and
Implementation, 2012. http://doi.acm.org/10.1145/2254064.2254114

[7] Matteo Frigo. 1999. A fast Fourier transform compiler. In
Proceedings of the ACM SIGPLAN 1999 conference on Programming language
design and implementation (PLDI '99). ACM, New York, NY, USA, 169-180.
DOI=10.1145/301618.301661 http://doi.acm.org/10.1145/301618.301661

[8] Karl Pettis and Robert C. Hansen. 1990. Profile guided code
positioning. In Proceedings of the ACM SIGPLAN 1990 conference on
Programming language design and implementation (PLDI '90). ACM, New
York, NY, USA, 16-27. DOI=10.1145/93542.93550
http://doi.acm.org/10.1145/93542.93550
