Evaluation:
 3 cases studies:

* Hypothesis: Profile Guided Optimizations expressed as Meta-programs
  can encode domain-specific knowledge, thus enabling previously
  impractical optimizations.

  Experiment: Consider the standard* profile-guided optimizaing of
  reordering `if` branches based on profile information. With the
  branches of an `if`, this is simple, since by definition the branches
  are mutually exclusive. But consider a multiple condition branching
  construct like C's `switch`. If the branches are not mutually
  exclusive or otherwise depend on order, it is not safe to reorder the
  branches. The compiler cannot perform this optimization without a
  clever analysis of the program, which in general will simply say "I
  don't know".

  If instead the programmer could say "I promise these branches are
  mutually exclusive", then the compiler could perform the optimization. 

  In this experiment, we demonstrate how we can use meta-programs to
  encode this information, and express such a construct.
  While simple, this optimization demonstrate the
  power of profile-guided meta-programming for optimization.
  Meta-programming allows us to extend the compiler with an previously
  unimplemented/impractical optimization and encode programmer knowledge
  into the program. 

* Hypothesis: Implementing Profile Guided Optimizations as Meta-programs

  is at least as powerful as the standard implementation technique
  (implementing a profiler and compiler), but substantially less effort.

  Experiment: Implement a minimal example of Perflint (Perflint uses
  list-to-vector and vector-to-list as the easy to explain example, and
  details their heuristic), with automatic data structure selection
  (which Perflint does not do). Compare programmer effort, lines of
  code, and system reuse (i.e. we just write a meta-program, no need to
  write tracers, trace-analyzers, since we reuse existing profiling
  system), and benchmark to show we get comparable improvements.

  Original work does not measure impact of following advice of perflint,
  instead focusing on overhead of perflint tracing. As our work uses
  prior work on low-overhead profiling, our overhead is very low in
  systems that implement the same profiling techniques. Racket does not
  yet implement all the overhead reducing techniques.

* Hypothesis: Implementing Profile Guided Optimizations as Meta-programs
  is at least as powerful as the standard implementation technique
  (implementing a profiler and compiler), but requires substantially
  less effort. Furthermore, PGOs as meta-programs can support
  optimizations, e.g., for DSLs, not supported by the host compiler,
  while standard PGO implementation (being implemented in the host
  compiler) can't.

  Experiment: 
  Implement polymorphic inline case and profile guided receiver class
  prediction via case in racket OO stuff. Compare programmer effort,
  lines of code, system reuse, and benchmark to show we get comparable
  improvements. Equivalent to 1-CCP from the paper, which gets most of
  the speedup anyway (the rest of the speedup is small enough to be
  noise, IMHO).
